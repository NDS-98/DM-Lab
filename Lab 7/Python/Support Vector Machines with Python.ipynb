{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Support Vector Machines with Python\n",
    "\n",
    "\n",
    "\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Classified Data',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.162073</td>\n",
       "      <td>0.567946</td>\n",
       "      <td>0.755464</td>\n",
       "      <td>0.780862</td>\n",
       "      <td>0.352608</td>\n",
       "      <td>0.759697</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>1.231409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.635632</td>\n",
       "      <td>1.003722</td>\n",
       "      <td>0.535342</td>\n",
       "      <td>0.825645</td>\n",
       "      <td>0.924109</td>\n",
       "      <td>0.648450</td>\n",
       "      <td>0.675334</td>\n",
       "      <td>1.013546</td>\n",
       "      <td>0.621552</td>\n",
       "      <td>1.492702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.721360</td>\n",
       "      <td>1.201493</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>1.526629</td>\n",
       "      <td>0.720781</td>\n",
       "      <td>1.626351</td>\n",
       "      <td>1.154483</td>\n",
       "      <td>0.957877</td>\n",
       "      <td>1.285597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.234204</td>\n",
       "      <td>1.386726</td>\n",
       "      <td>0.653046</td>\n",
       "      <td>0.825624</td>\n",
       "      <td>1.142504</td>\n",
       "      <td>0.875128</td>\n",
       "      <td>1.409708</td>\n",
       "      <td>1.380003</td>\n",
       "      <td>1.522692</td>\n",
       "      <td>1.153093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.279491</td>\n",
       "      <td>0.949750</td>\n",
       "      <td>0.627280</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>1.232537</td>\n",
       "      <td>0.703727</td>\n",
       "      <td>1.115596</td>\n",
       "      <td>0.646691</td>\n",
       "      <td>1.463812</td>\n",
       "      <td>1.419167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0  0.913917  1.162073  0.567946  0.755464  0.780862  0.352608  0.759697   \n",
       "1  0.635632  1.003722  0.535342  0.825645  0.924109  0.648450  0.675334   \n",
       "2  0.721360  1.201493  0.921990  0.855595  1.526629  0.720781  1.626351   \n",
       "3  1.234204  1.386726  0.653046  0.825624  1.142504  0.875128  1.409708   \n",
       "4  1.279491  0.949750  0.627280  0.668976  1.232537  0.703727  1.115596   \n",
       "\n",
       "        PJF       HQE       NXJ  TARGET CLASS  \n",
       "0  0.643798  0.879422  1.231409             1  \n",
       "1  1.013546  0.621552  1.492702             0  \n",
       "2  1.154483  0.957877  1.285597             0  \n",
       "3  1.380003  1.522692  1.153093             1  \n",
       "4  0.646691  1.463812  1.419167             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
      "0    0.913917  1.162073  0.567946  0.755464  0.780862  0.352608  0.759697   \n",
      "1    0.635632  1.003722  0.535342  0.825645  0.924109  0.648450  0.675334   \n",
      "2    0.721360  1.201493  0.921990  0.855595  1.526629  0.720781  1.626351   \n",
      "3    1.234204  1.386726  0.653046  0.825624  1.142504  0.875128  1.409708   \n",
      "4    1.279491  0.949750  0.627280  0.668976  1.232537  0.703727  1.115596   \n",
      "5    0.833928  1.523302  1.104743  1.021139  1.107377  1.010930  1.279538   \n",
      "6    0.944705  1.251761  1.074885  0.286473  0.996440  0.428860  0.910805   \n",
      "7    0.816174  1.088392  0.895343  0.243860  0.943123  1.045131  1.146536   \n",
      "8    0.776551  1.463812  0.783825  0.337278  0.742215  1.072756  0.880300   \n",
      "9    0.772280  0.515111  0.891596  0.940862  1.430568  0.885876  1.205231   \n",
      "10   1.284999  1.331018  0.618910  0.657017  1.037191  0.717346  0.778501   \n",
      "11   1.064356  1.414885  0.896798  0.629088  1.447704  0.791923  0.921676   \n",
      "12   0.682953  1.254723  0.998870  0.397701  1.011621  0.567863  1.335120   \n",
      "13   0.953318  1.318987  0.562921  0.905503  1.248314  0.677795  1.017305   \n",
      "14   0.801268  0.936390  0.696960  0.972440  0.851299  1.443119  1.194476   \n",
      "15   1.061691  1.044892  0.599729  0.465285  0.930288  0.974341  1.213450   \n",
      "16   0.715645  1.378594  0.997797  0.674996  1.228928  1.223293  0.589346   \n",
      "17   0.899792  1.225875  1.330887  0.335989  1.273570  1.100361  1.019617   \n",
      "18   0.883813  1.275891  0.924066  0.668814  1.269021  1.382093  0.728286   \n",
      "19   0.768311  1.394304  0.823118  0.612072  1.267414  0.881943  1.104178   \n",
      "20   1.252864  1.661820  0.922198  0.875100  1.413852  1.330486  0.897273   \n",
      "21   0.612488  1.338981  1.072606  0.799193  0.722667  1.139863  0.952153   \n",
      "22   0.661652  0.603561  0.884153  0.484525  0.832281  1.094654  1.156142   \n",
      "23   1.277638  0.925003  0.170924  1.057583  0.995938  0.934053  0.877794   \n",
      "24   1.109953  1.363461  0.647339  0.368138  1.340851  1.088502  1.071250   \n",
      "25   0.576839  1.319069  1.115112  1.131965  1.512161  0.954664  1.101880   \n",
      "26   0.855927  0.859602  0.834234  0.905675  1.187995  1.398766  0.907756   \n",
      "27   0.912403  0.935639  0.527303  0.669538  0.979297  0.769600  0.534440   \n",
      "28   0.677778  1.040820  0.655777  0.479425  1.119399  1.226695  0.971849   \n",
      "29   1.393081  1.193559  0.766170  0.961150  1.225038  1.129904  0.634757   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "970  0.633387  1.004500  1.248108  1.059318  1.301176  0.913190  1.027950   \n",
      "971  0.356470  1.182657  0.672876  1.068392  0.531516  1.254725  1.256490   \n",
      "972  1.142004  1.194030  1.299440  0.736344  1.411419  0.961965  0.750759   \n",
      "973  0.335992  1.343007  0.826096  0.843359  0.957316  0.879287  1.300711   \n",
      "974  0.804679  0.737121  0.332621  0.666363  1.018735  0.688024  1.296284   \n",
      "975  1.597781  0.927659  0.554321  0.750673  0.902208  0.984784  1.341203   \n",
      "976  0.876415  0.839314  1.179024  0.255085  1.439665  0.826521  0.731261   \n",
      "977  0.921677  1.361663  1.259150  0.649922  1.370695  1.405885  1.084434   \n",
      "978  0.372314  0.975962  0.549580  0.519043  1.156110  1.103559  1.218810   \n",
      "979  1.407042  0.999632  0.414295  0.598367  1.170322  1.001342  0.831199   \n",
      "980  0.888072  0.757363  1.427844  0.841364  1.203507  0.784256  0.738744   \n",
      "981  1.174795  1.018376  0.696083  0.269121  1.115722  1.526139  1.003034   \n",
      "982  0.935199  0.796759  0.803251  0.684983  1.081238  0.824708  0.772558   \n",
      "983  1.260558  0.610045  0.578569  0.524584  1.121035  0.737434  1.201745   \n",
      "984  0.961599  1.122676  0.231524  0.866719  1.385338  0.885569  0.704372   \n",
      "985  1.150205  0.726369  0.858908  0.750856  0.639816  0.495082  0.816259   \n",
      "986  0.335641  1.078280  0.961443  0.621197  1.294154  1.287877  0.847741   \n",
      "987  0.857298  0.759034  0.805310  0.634149  1.037998  0.824160  0.857125   \n",
      "988  0.612156  1.354874  1.147571  0.734393  1.308312  1.048704  0.906302   \n",
      "989  0.480687  1.240192  0.754194  0.804619  1.332328  0.893437  1.079114   \n",
      "990  0.876112  0.942414  1.060605  1.478041  0.818773  1.473635  1.306364   \n",
      "991  1.102612  1.007163  0.535051  0.633220  0.736791  0.864663  1.080128   \n",
      "992  0.809627  1.602700  0.990945  0.649933  1.118883  0.899837  0.919117   \n",
      "993  0.733687  1.049636  0.729194  0.851512  1.552015  0.954450  0.469426   \n",
      "994  1.212650  0.839062  0.456012  0.773420  1.091210  0.794378  0.736621   \n",
      "995  1.010953  1.034006  0.853116  0.622460  1.036610  0.586240  0.746811   \n",
      "996  0.575529  0.955786  0.941835  0.792882  1.414277  1.269540  1.055928   \n",
      "997  1.135470  0.982462  0.781905  0.916738  0.901031  0.884738  0.386802   \n",
      "998  1.084894  0.861769  0.407158  0.665696  1.608612  0.943859  0.855806   \n",
      "999  0.837460  0.961184  0.417006  0.799784  0.934399  0.424762  0.778234   \n",
      "\n",
      "          PJF       HQE       NXJ  \n",
      "0    0.643798  0.879422  1.231409  \n",
      "1    1.013546  0.621552  1.492702  \n",
      "2    1.154483  0.957877  1.285597  \n",
      "3    1.380003  1.522692  1.153093  \n",
      "4    0.646691  1.463812  1.419167  \n",
      "5    1.280677  0.510350  1.528044  \n",
      "6    0.755305  1.111800  1.110842  \n",
      "7    1.341886  1.225324  1.425784  \n",
      "8    1.312951  1.118165  1.225922  \n",
      "9    0.596858  1.542580  0.981879  \n",
      "10   0.599317  1.245676  1.441695  \n",
      "11   1.237249  0.564281  1.423668  \n",
      "12   1.093735  0.847015  1.374779  \n",
      "13   0.528065  1.541712  1.118960  \n",
      "14   1.641496  1.118737  1.426573  \n",
      "15   1.247551  1.217625  1.623154  \n",
      "16   1.559900  0.845324  1.248714  \n",
      "17   1.223891  1.113441  1.490151  \n",
      "18   0.726723  0.975833  1.653815  \n",
      "19   1.660998  0.742885  1.098704  \n",
      "20   1.280972  0.736994  1.192966  \n",
      "21   1.741919  1.021007  1.199203  \n",
      "22   1.351979  0.843353  1.489208  \n",
      "23   1.024684  1.393101  1.228411  \n",
      "24   1.132471  0.794287  1.378460  \n",
      "25   1.027592  1.253367  1.590563  \n",
      "26   0.866683  1.720440  1.428350  \n",
      "27   0.697452  0.985916  1.541798  \n",
      "28   1.087090  0.365157  1.167239  \n",
      "29   0.509353  1.380975  1.406252  \n",
      "..        ...       ...       ...  \n",
      "970  1.104102  0.945929  1.829285  \n",
      "971  1.212256  0.995391  1.213529  \n",
      "972  1.102159  0.780526  1.701120  \n",
      "973  1.491727  1.100409  1.167220  \n",
      "974  1.202599  1.269676  1.191833  \n",
      "975  0.960498  1.276498  1.415217  \n",
      "976  1.124331  0.853887  1.198824  \n",
      "977  1.424085  0.799699  1.379602  \n",
      "978  0.727332  0.882541  0.989175  \n",
      "979  1.126541  1.503445  1.054603  \n",
      "980  1.160597  0.530755  1.564079  \n",
      "981  1.005515  1.005263  1.228643  \n",
      "982  0.997079  1.456454  1.720509  \n",
      "983  0.680459  1.048840  1.384235  \n",
      "984  1.344190  0.972178  0.916688  \n",
      "985  0.472181  1.263450  1.232706  \n",
      "986  1.129603  0.932976  1.440056  \n",
      "987  1.693686  1.202474  1.418148  \n",
      "988  1.475490  1.050995  1.544443  \n",
      "989  0.819849  1.337147  1.547584  \n",
      "990  1.297386  0.522877  1.286394  \n",
      "991  1.230731  1.180497  1.677409  \n",
      "992  1.608892  0.978616  1.275621  \n",
      "993  0.862135  1.464802  1.088759  \n",
      "994  1.162377  1.512756  1.415168  \n",
      "995  0.319752  1.117340  1.348517  \n",
      "996  0.713193  0.958684  1.663489  \n",
      "997  0.389584  0.919191  1.385504  \n",
      "998  1.061338  1.277456  1.188063  \n",
      "999  0.907962  1.257190  1.364837  \n",
      "\n",
      "[1000 rows x 10 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      1\n",
       "10     1\n",
       "11     0\n",
       "12     0\n",
       "13     1\n",
       "14     0\n",
       "15     1\n",
       "16     0\n",
       "17     0\n",
       "18     0\n",
       "19     0\n",
       "20     0\n",
       "21     0\n",
       "22     0\n",
       "23     1\n",
       "24     0\n",
       "25     0\n",
       "26     1\n",
       "27     1\n",
       "28     0\n",
       "29     1\n",
       "      ..\n",
       "970    0\n",
       "971    0\n",
       "972    0\n",
       "973    0\n",
       "974    1\n",
       "975    1\n",
       "976    0\n",
       "977    0\n",
       "978    0\n",
       "979    1\n",
       "980    0\n",
       "981    0\n",
       "982    1\n",
       "983    1\n",
       "984    1\n",
       "985    1\n",
       "986    0\n",
       "987    0\n",
       "988    0\n",
       "989    1\n",
       "990    0\n",
       "991    1\n",
       "992    0\n",
       "993    1\n",
       "994    1\n",
       "995    1\n",
       "996    0\n",
       "997    1\n",
       "998    1\n",
       "999    1\n",
       "Name: TARGET CLASS, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('TARGET CLASS',axis=1)\n",
    "y = df['TARGET CLASS']\n",
    "print(X)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, np.ravel(y), test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Evaluations\n",
    "\n",
    "Now let's predict using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[155   4]\n",
      " [  9 132]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96       159\n",
      "          1       0.97      0.94      0.95       141\n",
      "\n",
      "avg / total       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch\n",
    "\n",
    "Finding the right parameters (like what C or gamma values to use) is a tricky task! But luckily, we can be a little lazy and just try a bunch of combinations and see what works best! This idea of creating a 'grid' of parameters and just trying out all the possible combinations is called a Gridsearch, this method is common enough that Scikit-learn has this functionality built in with GridSearchCV! \n",
    "\n",
    "GridSearchCV takes a dictionary that describes the parameters that should be tried and a model to train. The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a meta-estimator. It takes an estimator like SVC, and creates a new estimator, that behaves exactly the same - in this case, like a classifier. You should add refit=True and choose verbose to whatever number you want, higher the number, the more verbose (verbose just means the text output describing the process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=1,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What fit does is a bit more involved then usual. First, it runs the same loop with cross-validation, to find the best parameter combination. Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# May take awhile!\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the best parameters found by GridSearchCV in the best_params_ attribute, and the best estimator in the best\\_estimator_ attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can re-run predictions on this grid object just like you would with a normal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[154   5]\n",
      " [  8 133]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96       159\n",
      "          1       0.96      0.94      0.95       141\n",
      "\n",
      "avg / total       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
